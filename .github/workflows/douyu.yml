name: Douyu Crawler

on:
  schedule:
    - cron: '*/1 * * * *'  # 每小时整点运行一次
  workflow_dispatch:  # 允许手动触发

jobs:
  build-and-run:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.x

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run the spider
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        OUTPUT_FILE: douyu.txt  # 定义文件名环境变量
      run: |
        python dy.py > "${OUTPUT_FILE}"  # 将输出重定向到文件
        echo "Crawling completed. Output file: ${OUTPUT_FILE}"

    - name: Check for output file
      run: |
        if [[ ! -f "${OUTPUT_FILE}" ]]; then
          echo "Output file not generated. Crawler may have failed."
          exit 1
        fi
        echo "Output file exists."

    - name: Upload results
      if: always()
      uses: actions/upload-artifact@v2
      with:
        name: douyu-results
        path: "${OUTPUT_FILE}"
